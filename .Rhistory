X[,(j+2)] = pmax(c(1:n) - cps[j], 0)
}
mod = lm(y ~ X)
log.value = ((ncol(X) - n)/2)*(log(sum(mod$residuals^2))) - (0.5*(log(det(t(X) %*% X))))
return(log.value)
}
logpost.max = logpost(c(3,4))
s.hat = c(0, 0) # MAP estimator for s
for (s1 in 3:(n-3)) {
for (s2 in (s1+1):(n-3)) {
m = logpost(c(s1, s2))
if (m > logpost.max) {
logpost.max = m
s.hat[1] = s1
s.hat[2] = s2
}
}
}
s.hat
for (s1 in 3:(10-3)) {
for (s2 in (s1+1):(10-3)) {
print(c(s1, s2))
}
}
for (s2 in 3:(10-3)) {
for (s1 in 3:(s2-1)) {
print(c(s1, s2))
}
}
for (s2 in 3:(10-3)) {
for (s1 in 3:(s2-1)) {
if (s1 >= s2) {continue}
print(c(s1, s2))
}
}
for (s2 in 3:(10-3)) {
for (s1 in 3:(s2-1)) {
if (s1 >= s2) {next}
print(c(s1, s2))
}
}
logpost.max = logpost(c(3,4))
s.hat = c(0, 0) # MAP estimator for s
# the for loops take 20 seconds
for (s1 in 3:(n-3)) {
for (s2 in (s1+1):(n-3)) {
if (s1 >= s2) {next}
m = logpost(c(s1, s2))
if (m > logpost.max) {
logpost.max = m
s.hat[1] = s1
s.hat[2] = s2
}
}
}
s.hat
1:1
for (s1 in 3:(n-3)) {
if (s1+1 > n-3) {
# then no need to go to the second for loop
# need this if statement, or (s1+1):(n-3) will cause bug when s1+1 > n-3
break
}
for (s2 in (s1+1):(n-3)) {
print(c(s1,s2))
}
}
for (s1 in 3:(10-3)) {
if (s1+1 > 10-3) {
# then no need to go to the second for loop
# need this if statement, or (s1+1):(n-3) will cause bug when s1+1 > n-3
break
}
for (s2 in (s1+1):(10-3)) {
print(c(s1,s2))
}
}
logpost.max = logpost(c(3,4))
s.hat = c(0, 0) # MAP estimator for s
# the nested for loops take 20 seconds
for (s1 in 3:(n-3)) {
if (s1+1 > n-3) {
# then no need to go to the second for loop
# need this if statement, or (s1+1):(n-3) will cause bug when s1+1 > n-3
break
}
for (s2 in (s1+1):(n-3)) {
m = logpost(c(s1, s2))
if (m > logpost.max) {
logpost.max = m
s.hat[1] = s1
s.hat[2] = s2
}
}
}
s.hat
logpost.matrix = matrix(0, nrow=n-3, ncol=n-3) # saves logpost(c(s1, s2)) so that we don't need
# to compute again
logpost.max = logpost(c(3,4))
s.hat = c(0, 0) # MAP estimator for s
# the nested for loops take 20 seconds
for (s1 in 3:(n-3)) {
if (s1+1 > n-3) {
# then no need to go to the second for loop
# need this if statement, or (s1+1):(n-3) will cause bug when s1+1 > n-3
break
}
for (s2 in (s1+1):(n-3)) {
m = logpost(c(s1, s2))
logpost.matrix[s1, s2] = m
if (m > logpost.max) {
logpost.max = m
s.hat[1] = s1
s.hat[2] = s2
}
}
}
post.s = matrix(0, nrow=n-3, ncol=n-3)
for (s1 in 3:(n-3)) {
if (s1+1 > n-3) {
# then no need to go to the second for loop
# need this if statement, or (s1+1):(n-3) will cause bug when s1+1 > n-3
break
}
for (s2 in (s1+1):(n-3)) {
post.s[s1, s2] = exp(logpost.matrix[s1, s2] - logpost.max)
}
}
logpost.matrix[1:20, 1:20]
post.s[1:20, 1:20]
post.s[s.hat[1], s.hat[2]]
?sum
A = matrix(c(1,2,3,4), nrow=2)
sum(A)
sum(post.s)
sum(post.s)
post.s[s.hat]
post.s[s.hat[1]-1, s.hat[2]]
post.s[s.hat[1]-1, s.hat[2]+1]
# normalize
post.s = post.s / sum(post.s)
post.s[s.hat[1], s.hat[2]]
A
apply(A, MARGIN=1, sum)
post.s1 = apply(post.s, MARGIN=1, sum)
post.s2 = apply(post.s, MARGIN=2, sum)
# normalize
post.s = matrix(0, nrow=n-3, ncol=n-3)
for (s1 in 3:(n-3)) {
if (s1+1 > n-3) {
# then no need to go to the second for loop
# need this if statement, or (s1+1):(n-3) will cause bug when s1+1 > n-3
break
}
for (s2 in (s1+1):(n-3)) {
post.s[s1, s2] = exp(logpost.matrix[s1, s2] - logpost.max)
}
}
post.s1 = apply(post.s, MARGIN=1, sum)
post.s2 = apply(post.s, MARGIN=2, sum)
# normalize
post.s1[1:20]
sum(post.s1)
sum(post.s2)
post.s = matrix(0, nrow=n-3, ncol=n-3)
for (s1 in 3:(n-3)) {
if (s1+1 > n-3) {
# then no need to go to the second for loop
# need this if statement, or (s1+1):(n-3) will cause bug when s1+1 > n-3
break
}
for (s2 in (s1+1):(n-3)) {
post.s[s1, s2] = exp(logpost.matrix[s1, s2] - logpost.max)
}
}
post.s1 = apply(post.s, MARGIN=1, sum)
post.s2 = apply(post.s, MARGIN=2, sum)
# normalize
post.s1 = post.s1 / sum(post.s1)
post.s2 = post.s2 / sum(post.s2)
post.s1[s.hat[1]]
d = 1
conf.total = post.s1[s.hat[1]]
while(conf.total <= .95) {
conf.total <- conf.total + post.s1[s.hat[1]-d] + post.s1[s.hat[1]+d]
d <- d + 1
}
c(s.hat[1]-d, s.hat[1]+d)
d = 1
conf.total = post.s2[s.hat[2]]
while(conf.total <= .95) {
conf.total <- conf.total + post.s2[s.hat[2]-d] + post.s2[s.hat[2]+d]
d <- d + 1
}
c(s.hat[2]-d, s.hat[2]+d)
plot(1:n, y, type='l')
abline(v=s_1, col='red')
plot(1:n, y, type='l')
abline(v=s.hat[1], col='red')
plot(1:n, y, type='l')
abline(v=s.hat[1], col='red')
abline(v=s.hat[2], col='red')
post.s1
length(post.s1) == n
length(post.s1)
n
post.s1
post.s1[3:]
post.s1[3:(n-3)]
post.s[100, ]/ post.s1[100]
sum(post.s[100, ]/ post.s1[100])
sum(post.s[100, ]/ post.s2[100])
sum(A)
post.s = matrix(0, nrow=n-3, ncol=n-3)
for (s1 in 3:(n-3)) {
if (s1+1 > n-3) {
# then no need to go to the second for loop
# need this if statement, or (s1+1):(n-3) will cause bug when s1+1 > n-3
break
}
for (s2 in (s1+1):(n-3)) {
post.s[s1, s2] = exp(logpost.matrix[s1, s2] - logpost.max)
}
}
# normalize
post.s = post.s / sum(post.s)
post.s1 = apply(post.s, MARGIN=1, sum)
post.s2 = apply(post.s, MARGIN=2, sum)
# normalize
post.s1 = post.s1 / sum(post.s1)
post.s2 = post.s2 / sum(post.s2)
d = 1
conf.total = post.s1[s.hat[1]]
while(conf.total <= .95) {
conf.total <- conf.total + post.s1[s.hat[1]-d] + post.s1[s.hat[1]+d]
d <- d + 1
}
c(s.hat[1]-d, s.hat[1]+d)
d = 1
conf.total = post.s2[s.hat[2]]
while(conf.total <= .95) {
conf.total <- conf.total + post.s2[s.hat[2]-d] + post.s2[s.hat[2]+d]
d <- d + 1
}
c(s.hat[2]-d, s.hat[2]+d)
?sample
post.s[20,]
?vapply
sapply(c(1,2,3), FUN=function(x){2*x})
c(1,2,3,4)-3
N = 2000 #number of posterior samples
# in post.samples, column 1, 2 is for samples from the distribution (s_1, s_2) | y
# column 3, 4, 5, 6 is for samples from (beta_0, ..., beta_3) | s_1, s_2, y
# equivalently, column 1 is for samples from s_1 | y
# and column 2 is for samples from s_2 | s_1, y
post.samples = matrix(-1, nrow=N, ncol=6)
post.samples[,1] = sample(3:(n-3), N, replace = T, prob = post.s1[3:(n-3)])
# s2.cond(s1) returns one sample from s_2 | s_1, y
s2.cond = function(s1) {
s2.range = (s1+1):(n-3)
cond.prob = post.s[s1, s2.range] / post.s1[s1] # conditional probability distribution represented by vector
sample(s2.range, size=1, prob=cond.prob)
}
post.samples[,2] = sapply(post.samples[,1], FUN=s2.cond)
# column 3, 4, 5, 6 is for samples from (beta_0, ..., beta_3) | s_1, s_2, y, which is multivariate t
for(i in 1:N)
{
p = 4
s1 = post.samples[i,1]
s2 = post.samples[i,2]
X = matrix(1, nrow = n, ncol = p)
X[,2] = 1:n
X[,3] = pmax(c(1:n) - s1, 0)
X[,4] = pmax(c(1:n) - s2, 0)
lin.model = lm(y ~ X)
bhat = lin.model$coefficients
sighat = sqrt((sum((lin.model$residuals)^2))/(n-p))
Sigma.mat = (sighat^2)*solve(t(X) %*% X)
chiran = rchisq(1, df = n-p)
beta.samples = bhat + (rmvnorm(1, sigma = Sigma.mat))/(sqrt(chiran/(n-p)))
post.samples[i, 3:6] = beta.samples
}
X = matrix(1, nrow = n, ncol = 2)
X[,2] = 1:n
mod = lm(y ~ X)
summary(mod)
X = matrix(1, nrow = n, ncol = 2)
X[,2] = 1:n
mod = lm(y ~ -1 + X)
summary(mod)
#cps: change of slope points s_1, s_2.
logpost = function(cps)
{
cps = sort(cps)
k = length(cps)
X = matrix(1, nrow = n, ncol = (k+2))
X[,2] = 1:n
for(j in 1:k)
{
X[,(j+2)] = pmax(c(1:n) - cps[j], 0)
}
mod = lm(y ~ -1 + X) # -1 is needed because the default provides an intercept term, but
# X already contains the intercept term
log.value = ((ncol(X) - n)/2)*(log(sum(mod$residuals^2))) - (0.5*(log(det(t(X) %*% X))))
return(log.value)
}
logpost.matrix = matrix(0, nrow=n-3, ncol=n-3) # saves logpost(c(s1, s2)) so that we don't need
# to compute again
logpost.max = logpost(c(3,4))
s.hat = c(0, 0) # MAP estimator for s
# the nested for loops take 20 seconds
for (s1 in 3:(n-3)) {
if (s1+1 > n-3) {
# then no need to go to the second for loop
# need this if statement, or (s1+1):(n-3) will cause bug when s1+1 > n-3
break
}
for (s2 in (s1+1):(n-3)) {
m = logpost(c(s1, s2))
logpost.matrix[s1, s2] = m
if (m > logpost.max) {
logpost.max = m
s.hat[1] = s1
s.hat[2] = s2
}
}
}
s.hat
post.s = matrix(0, nrow=n-3, ncol=n-3)
for (s1 in 3:(n-3)) {
if (s1+1 > n-3) {
# then no need to go to the second for loop
# need this if statement, or (s1+1):(n-3) will cause bug when s1+1 > n-3
break
}
for (s2 in (s1+1):(n-3)) {
post.s[s1, s2] = exp(logpost.matrix[s1, s2] - logpost.max)
}
}
# normalize
post.s = post.s / sum(post.s)
post.s1 = apply(post.s, MARGIN=1, sum)
post.s2 = apply(post.s, MARGIN=2, sum)
# normalize
post.s1 = post.s1 / sum(post.s1)
post.s2 = post.s2 / sum(post.s2)
d = 1
conf.total = post.s1[s.hat[1]]
while(conf.total <= .95) {
conf.total <- conf.total + post.s1[s.hat[1]-d] + post.s1[s.hat[1]+d]
d <- d + 1
}
c(s.hat[1]-d, s.hat[1]+d)
d = 1
conf.total = post.s2[s.hat[2]]
while(conf.total <= .95) {
conf.total <- conf.total + post.s2[s.hat[2]-d] + post.s2[s.hat[2]+d]
d <- d + 1
}
c(s.hat[2]-d, s.hat[2]+d)
N = 2000 #number of posterior samples
# in post.samples, column 1, 2 is for samples from the distribution (s_1, s_2) | y
# column 3, 4, 5, 6 is for samples from (beta_0, ..., beta_3) | s_1, s_2, y
# equivalently, column 1 is for samples from s_1 | y
# and column 2 is for samples from s_2 | s_1, y
post.samples = matrix(-1, nrow=N, ncol=6)
post.samples[,1] = sample(3:(n-3), N, replace = T, prob = post.s1[3:(n-3)])
# s2.cond(s1) returns one sample from s_2 | s_1, y
s2.cond = function(s1) {
s2.range = (s1+1):(n-3)
cond.prob = post.s[s1, s2.range] / post.s1[s1] # conditional probability distribution represented by vector
sample(s2.range, size=1, prob=cond.prob)
}
post.samples[,2] = sapply(post.samples[,1], FUN=s2.cond)
# column 3, 4, 5, 6 is for samples from (beta_0, ..., beta_3) | s_1, s_2, y, which is multivariate t
for(i in 1:N)
{
p = 4
s1 = post.samples[i,1]
s2 = post.samples[i,2]
X = matrix(1, nrow = n, ncol = p)
X[,2] = 1:n
X[,3] = pmax(c(1:n) - s1, 0)
X[,4] = pmax(c(1:n) - s2, 0)
lin.model = lm(y ~ -1 + X)
bhat = lin.model$coefficients
sighat = sqrt((sum((lin.model$residuals)^2))/(n-p))
Sigma.mat = (sighat^2)*solve(t(X) %*% X)
chiran = rchisq(1, df = n-p)
beta.samples = bhat + (rmvnorm(1, sigma = Sigma.mat))/(sqrt(chiran/(n-p)))
post.samples[i, 3:6] = beta.samples
}
s.hat
# get beta hat
X = matrix(1, nrow = n, ncol = p)
X[,2] = 1:n
X[,3] = pmax(c(1:n) - s.hat[1], 0)
X[,4] = pmax(c(1:n) - s.hat[2], 0)
lin.model = lm(y ~ -1 + X)
best.bhat = lin.model$coefficients
best.bhat
?lines
plot(1:n, y, type='l')
lines(lin.model$fitted.values)
plot(1:n, y, type='l')
lines(lin.model$fitted.values, col='red')
quantile(post.samples[,3], c(.025, .975))
quantile(post.samples[,3], c(.025, .975))
quantile(post.samples[,4], c(.025, .975))
quantile(post.samples[,5], c(.025, .975))
quantile(post.samples[,6], c(.025, .975))
?plot
plot(1:n, y, type='p')
lines(lin.model$fitted.values, col='red')
plot(1:n, y, type='l')
lines(lin.model$fitted.values, col='red')
plot(1:n, y, type='l')
lines(lin.model$fitted.values, col='red')
par(xlab='t')
plot(1:n, y, type='l', xlab='t')
lines(lin.model$fitted.values, col='red')
plot(lin.model$residuals)
plot(lin.model$residuals, type='l')
plot(lin.model$residuals, type='l')
acf(lin.model$residuals)
plot(lin.model$residuals, type='l')
acf(lin.model$residuals, lag.max=100)
plot(lin.model$residuals, type='l')
acf(lin.model$residuals, lag.max=10)
plot(lin.model$residuals, type='l')
acf(lin.model$residuals)
quantile(post.samples[,6], c(.025, .975))
plot(lin.model$residuals, type='l')
acf(lin.model$residuals)
plot(lin.model$residuals, type='l')
acf(lin.model$residuals)
plot(lin.model$residuals, type='l')
acf(lin.model$residuals, lag.max=100)
plot(lin.model$residuals, type='l')
acf(lin.model$residuals, lag.max=300)
plot(lin.model$residuals, type='l')
acf(lin.model$residuals, lag.max=300)
golf <- read.csv('golf.csv', skip=1, header=T)
head(golf)
y = golf[,2]
n = length(y)
t = 1:n
plot(t, y, type='l')
n_half = as.integer(n/2)
pgram = abs(fft(y)[2:50])^2 / n # peaks at 19
plot(pgram, type='h')
225/19 # roughly 12. As expected, we have yearly trend
log.post.f = function(f) {
X = matrix(1, nrow=n, ncol=5)
X[,2] = t
X[,3] = t^2
X[,4] = cos(2*pi*f*t)
X[,5] = sin(2*pi*f*t)
lin.mod = lm(y ~ 1 + X[,2] + X[,3] + X[,4] + X[,5])
-log(det(t(X) %*% X))/2 - log(sum((lin.mod$residuals)^2))*(n-5)/2
}
x = seq(10, 14, by=.01)
plot(1/x, as.numeric(lapply(1/x, FUN=log.post.f)), type='l')
opt = optimize(log.post.f, interval=c(.080, .085), maximum = T)
f.hat = opt$maximum
log.post.f.max = opt$objective
post.f = function(f) {
exp(log.post.f(f) - log.post.f.max)
}
1/f.hat # very close to 12
plot(1/x, as.numeric(lapply(1/x, FUN=post.f)), type='l')
?integrate
integrate(post.f, lower=f.hat-0.05, f.hat+0.05)
post.f(1/12) # 1/12 is even better than f.hat, kind of weird
post.f(f.hat)
integrate(post.f, lower=f.hat-.001, f.hat+.001)
integrate(function(x){x^2}, lower=0, upper=1)
integrate(log.post.f, lower=f.hat-.001, f.hat+.001)
log.post.f(0.05
)
post.f(f.hat-.01)
post.f(f.hat-.005)
# gridding
# consider fixed sequence of values
# 1/12 +- 0.0001*2^n
# see the pdfs each term of the sequence maps
res = .00001 # resolution
my.grid = seq(f.hat-.005, f.hat+.005, by=res)
total.integral = 0
for (x in my.grid) {
total.integral = total.integral + res*post.f(x)
}
total.integral
post.f = function(x) {
post.f(x) / total.integral
}
plot(1/x, as.numeric(lapply(1/x, FUN=post.f)), type='l')
opt = optimize(log.post.f, interval=c(.080, .085), maximum = T)
f.hat = opt$maximum
log.post.f.max = opt$objective
post.f.0 = function(f) { # posterior f but not normalized
exp(log.post.f(f) - log.post.f.max)
}
res = .00001 # resolution
my.grid = seq(f.hat-.005, f.hat+.005, by=res)
total.integral = 0
for (x in my.grid) {
total.integral = total.integral + res*post.f(x)
}
post.f = function(f) {
post.f.0(f) / total.integral
}
