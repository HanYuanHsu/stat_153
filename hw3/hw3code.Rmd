---
title: "hw3code"
author: "Han-Yuan Hsu"
date: '2022-10-04'
output: pdf_document
---
```{r}
library(dplyr)
set.seed(111)
```

# 1
A noisy measurement device is being examined for understanding the distribution of
the errors that are being produced by it. Suppose that ten measurements led to the
following observations on the errors made by the device:
```{r}
err = c(-0.69, -4.26, 0.14, -0.86, 0.42, 24.21, 0.51, -1.23, 2.30, 4.15)
```

## a
```{r}
lik1 = function(sigma) {
  if (sigma==0) {return(0)} # the formula below is undefined for sigma=0, but the limit is 0
  
  1/(sqrt(2*pi)*sigma)^10 * exp(-sum(err^2)/2/sigma^2)
}

lik2 = function(sigma) {
  if (sigma==0) {return(0)}
  
  1/(2*sigma)^10 * exp(-sum(abs(err))/sigma)
}

lik3 = function(sigma) {
  prod = 1
  for (i in 1:10) {
    term = sigma / (err[i]^2 + sigma^2) / pi 
    prod = prod * term
  }
  prod
}
```


The range of the integrals is $(e^{-15}, e^{15})$, but $e^{15}$ is too large for numerical integration. The following shows integrating up to 100 does a good approximation:
```{r}
lik1(100)
lik2(100)
lik3(100)
```


```{r}
res = .001
my.grid = seq(exp(-15), 100+exp(-15), by=res)

lik1.vals = sapply(my.grid, FUN=lik1)
evid1 = 1/30 * sum(lik1.vals / my.grid) * res

lik2.vals = sapply(my.grid, FUN=lik2)
evid2 = 1/30 * sum(lik2.vals / my.grid) * res

lik3.vals = sapply(my.grid, FUN=lik3)
evid3 = 1/30 * sum(lik3.vals / my.grid) * res

```

The evidences:
```{r}
evid1
evid2
evid3
```


## b
Normalize the three evidences to obtain posterior probabilities for the three models.
Which model has the highest posterior probability? Comment on whether
your results seem intutively sensible. (2 points).

```{r}
normalizing.const = evid1 + evid2 + evid3
evid1 / normalizing.const
evid2 / normalizing.const
evid3 / normalizing.const
```
Model 3 has the highest posterior probability. That makes sense -- Cauchy distribution has the fattest tail compared with the distrbutions of the other two models that decay exponentially. The error data has an outlier 24.21, so a heavy-tail distribtuion makes this outlier more possible. 

\newpage
# 2
```{r}
dat = read.csv('HW3Data153Fall2022.csv')
head(dat)
n = length(dat$x)
```
```{r}
plot(dat$x, dat$y)
```



## a
Numerically calculate the Evidence for each of these models given the observed
data. Report the normalized evidences. Which model has the highest evidence and
what is the value of this highest evidence? (6 points)

```{r}
beta0.vals = seq(-10, 10, by=.1)
beta1.vals = seq(-10, 10, by=.1)
sig.vals = exp(seq(-10, 10, by=.1))
vals.length = length(beta0.vals)

loglik1 = function(param) {
  b0 = param[1]; b1 = param[2]; sig = param[3]
  n*(log(sig)-log(pi)) - sum(log((dat$y - b1*dat$x - b0)^2 + sig^2))
}

loglik2 = function(param) {
  b0 = param[1]; b1 = param[2]; sig = param[3]
  -n*log(2*sig) - sum(abs(dat$y - b1*dat$x - b0))/sig
}

loglik3 = function(param) {
  b0 = param[1]; sig = param[2]
  n*(log(sig)-log(pi)) - sum(log((dat$y - b0)^2 + sig^2))
}

loglik4 = function(param) {
  b0 = param[1]; sig = param[2]
  -n*log(2*sig) - sum(abs(dat$y - b0))/sig
}
```

expand grid and apply loglik1
subtract max
exp
normalize

```{r}
vals = expand.grid(beta0.vals, beta1.vals, sig.vals)
```
```{r}
#loglik1.vals = apply(vals, MARGIN=1, FUN=loglik1) # takes 3 minutes
#save(loglik1.vals, file='loglik1.vals.RData')
load(file='loglik1.vals.RData')
```
```{r}
loglik1.vals.max = max(loglik1.vals)
loglik1.vals = loglik1.vals - loglik1.vals.max
lik1.vals = exp(loglik1.vals) # the true likelihood values should be this times exp(loglik1.vals.max)
```

Below, the true evidence of model 1 is proportional to `evid1.scaled` times exp(`loglik1.vals.max`), where
the proportionality constant is the same for all four models. So, to choose the best model, we find the largest `evidm.scaled` times exp(`loglikm.vals.max`) for m=1,2,3,4.
```{r}
evid1.scaled = sum(lik1.vals) # I didn't multiply the prior here because it is the same for all 4 models
evid1.scaled
loglik1.vals.max
```

```{r}
#loglik2.vals = apply(vals, MARGIN=1, FUN=loglik2)
#save(loglik2.vals, file='loglik2.vals.RData')
load(file='loglik2.vals.RData')
```

```{r}
loglik2.vals.max = max(loglik2.vals)
loglik2.vals = loglik2.vals - loglik2.vals.max
lik2.vals = exp(loglik2.vals) # the true likelihood values should be this times exp(loglik2.vals.max)
```
```{r}
evid2.scaled = sum(lik2.vals)
evid2.scaled
loglik2.vals.max
```


```{r}
vals2 = expand.grid(beta0.vals, sig.vals)
```

```{r}
#loglik3.vals = apply(vals2, MARGIN=1, FUN=loglik3)
#save(loglik3.vals, file='loglik3.vals.RData')
#loglik4.vals = apply(vals2, MARGIN=1, FUN=loglik4)
#save(loglik4.vals, file='loglik4.vals.RData')
load('loglik3.vals.RData')
load('loglik4.vals.RData')
```

```{r}
loglik3.vals.max = max(loglik3.vals)
loglik3.vals = loglik3.vals - loglik3.vals.max
lik3.vals = exp(loglik3.vals) # the true likelihood values should be this times exp(loglik3.vals.max)
```
```{r}
evid3.scaled = sum(lik3.vals)
evid3.scaled
loglik3.vals.max
```
```{r}
loglik4.vals.max = max(loglik4.vals)
loglik4.vals = loglik4.vals - loglik4.vals.max
lik4.vals = exp(loglik4.vals) # the true likelihood values should be this times exp(loglik3.vals.max)
```
```{r}
evid4.scaled = sum(lik4.vals)
evid4.scaled
loglik4.vals.max
```

Calculate normalized evidences:
```{r}
evid1 = evid1.scaled
evid2 = evid2.scaled * exp(loglik2.vals.max - loglik1.vals.max)
evid3 = evid3.scaled * exp(loglik3.vals.max - loglik1.vals.max)
evid4 = evid4.scaled * exp(loglik4.vals.max - loglik1.vals.max)
normalizing.const = evid1 + evid2 + evid3 + evid4
evid1 = evid1 / normalizing.const
evid2 = evid2 / normalizing.const
evid3 = evid3 / normalizing.const
evid4 = evid4 / normalizing.const
```
```{r}
evid1 # should be almost 1
evid2
evid3
evid4
```
Model 1 has the highest evidence, with an evidence almost 1 because the evidences for other models are very small.

## b
```{r}
ind.max = which.max(loglik1.vals)
beta0.hat = vals[ind.max, 1]
beta1.hat = vals[ind.max, 2]
sig.hat = vals[ind.max, 3]
```
```{r}
beta0.hat
beta1.hat
sig.hat
```
Below, the red line is $\hat\beta_0 + \hat\beta_1 x$:
```{r}
plot(dat$x, dat$y)
abline(beta0.hat, beta1.hat, col='red')
```

To get uncertainty quantification for the parameters, we sample from the posterior distribution:
```{r}
N = 1000000
post.pdf = lik1.vals / sum(lik1.vals) # posterior pdf of beta0, beta1, sigma
ind.samples = sample(1:nrow(vals), N, replace=T, prob=post.pdf)
beta0.samples = vals[ind.samples, 1]
beta1.samples = vals[ind.samples, 2]
sig.samples = vals[ind.samples, 3]
```

Below are the probabilities of each parameter equaling its estimator:
```{r}
sum(beta0.samples == beta0.hat) / length(beta0.samples)
sum(beta1.samples == beta1.hat) / length(beta1.samples)
sum(sig.samples == sig.hat) / length(sig.samples)
```
Below is a 95% credibility interval for sigma:
```{r}
quantile(sig.samples, c(.025, .975))
```
\newpage
# 3
R has an inbuilt dataset called state which gives some data on 50 states in America
from the 1970s. You can access this dataset via (see help(state) for information
about the data)
We want to fit a linear model to this dataset with life expectancy as the response
variable and some subset of the remaining seven explanatory variables (including the
intercept term). Your goal is to figure out which subset of the explanatory variables
provides the best explanation for the response variable in a linear model.

```{r}
data(state); dt = data.frame(state.x77, row.names = state.abb)
head(dt)
```


## a
Use the Evidence-based Bayesian model selection method from Lecture 11 to
calculate the evidences for each of the 2^7 = 128 models (obtaining by taking all
possible subsets of the explanatory variables along with the intercept term). How
many of the 128 models get nontrivial Evidences (after normalization so that the
Evidences sum to one)? Describe the models getting high evidences? Do the
results of your analysis seem sensible? (6 points)



